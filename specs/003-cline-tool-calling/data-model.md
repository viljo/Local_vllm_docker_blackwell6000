# Data Model: Tool Calling Support

**Feature**: 003-cline-tool-calling
**Date**: 2025-11-12

## Overview

This document defines the data entities and their relationships for OpenAI-compatible tool calling support. All models are defined in terms of their logical structure and validation rules, independent of implementation technology.

---

## Core Entities

### 1. Chat Message

Represents a single message in a conversation, supporting multiple roles including tool results.

**Fields**:
- `role` (string, required): Message role
  - Valid values: `"system"`, `"user"`, `"assistant"`, `"tool"`
  - Validation: Must be non-empty string
- `content` (string, optional): Message content
  - Can be `null` when `tool_calls` are present
  - For `role: "tool"`, contains the function execution result
- `tool_calls` (array of Tool Call, optional): Function calls to execute
  - Only valid when `role: "assistant"`
  - Mutually exclusive with text-only content (though both can coexist)
- `tool_call_id` (string, optional): ID of the tool call this message responds to
  - Only valid when `role: "tool"`
  - Must match an ID from a previous assistant message's `tool_calls`
- `name` (string, optional): Function or tool name
  - Used for clarity in tool messages
  - Not required but recommended

**Relationships**:
- A Chat Message belongs to a Chat Completion Request
- A Chat Message with `role: "assistant"` may contain multiple Tool Calls
- A Chat Message with `role: "tool"` references one Tool Call via `tool_call_id`

**Validation Rules**:
1. If `role` is `"tool"`, `tool_call_id` must be present
2. If `role` is `"tool"`, `content` must be present
3. If `role` is `"assistant"` and `tool_calls` is present, `content` may be `null`
4. `tool_call_id` must match a tool call ID from a previous message

**State Transitions**:
- User message → Assistant message (with or without tool_calls)
- Assistant message with tool_calls → One or more tool messages
- Tool message(s) → Assistant message (final response)

---

### 2. Tool Call

Represents a specific invocation of a function by the assistant.

**Fields**:
- `id` (string, required): Unique identifier for this tool call
  - Format: Must start with `"call_"` followed by alphanumeric characters
  - Example: `"call_abc123xyz"`
  - Validation: Regex pattern `^call_[a-zA-Z0-9]+$`
  - Must be unique within the conversation
- `type` (string, required): Type of tool call
  - Currently only `"function"` is supported
  - Validation: Must equal `"function"`
- `function` (Function Invocation, required): The function to call with arguments

**Relationships**:
- A Tool Call belongs to a Chat Message with `role: "assistant"`
- A Tool Call is referenced by a Tool Result Message via `tool_call_id`
- Multiple Tool Calls can exist in a single assistant message (parallel execution)

**Validation Rules**:
1. `id` must be unique across all tool calls in the conversation
2. `type` must be `"function"`
3. `function` must be a valid Function Invocation object

**ID Generation**:
- Generated by the API when creating tool calls
- Must be cryptographically random to ensure uniqueness
- Length typically 24-32 characters after `"call_"` prefix

---

### 3. Function Invocation

Represents the actual function call with its arguments.

**Fields**:
- `name` (string, required): Name of the function to call
  - Must match a function name from the `tools` array in the request
  - Validation: Non-empty string, matches `^[a-zA-Z0-9_-]+$`
- `arguments` (string, required): JSON string containing function arguments
  - **Important**: This is a JSON string, not a JSON object
  - Must be valid JSON when parsed
  - Should conform to the parameters schema defined in the tool definition
  - Example: `"{\"path\":\"/tmp/test.txt\",\"encoding\":\"utf-8\"}"`

**Relationships**:
- A Function Invocation belongs to a Tool Call
- The function name references a Tool Definition from the request

**Validation Rules**:
1. `name` must match a tool in the request's `tools` array
2. `arguments` must be a valid JSON string (can be parsed with JSON.parse/json.loads)
3. Parsed arguments should match the JSON Schema in the Tool Definition's `parameters`
4. Required parameters (per schema) must be present in arguments

**Error Conditions**:
- Function name not found in tools → Error: `unknown_tool_call`
- Invalid JSON in arguments → Error: `malformed_tool_arguments`
- Missing required parameters → Error: `invalid_tool_arguments`
- Type mismatch in parameters → Error: `invalid_tool_arguments`

---

### 4. Tool Definition

Represents a function available for the assistant to call.

**Fields**:
- `type` (string, required): Type of tool
  - Always `"function"` (currently the only supported type)
  - Validation: Must equal `"function"`
- `function` (Tool Function, required): The function definition

**Relationships**:
- A Tool Definition belongs to a Chat Completion Request
- Multiple Tool Definitions can exist in a request
- Tool Definitions are referenced by Function Invocations via function name

**Validation Rules**:
1. `type` must be `"function"`
2. `function` must be a valid Tool Function object
3. Function names must be unique within the `tools` array

---

### 5. Tool Function

Describes a specific function with its signature and behavior.

**Fields**:
- `name` (string, required): Function identifier
  - Format: Alphanumeric with underscores/hyphens
  - Validation: Regex `^[a-zA-Z0-9_-]+$`
  - Example: `"read_file"`, `"get_weather"`
- `description` (string, optional): Human-readable function description
  - Helps the model understand when to use this function
  - Recommended to include clear, concise description
  - Example: `"Read the contents of a file at the specified path"`
- `parameters` (JSON Schema object, required): Function parameter schema
  - Must be a valid JSON Schema object
  - Root type must be `"object"`
  - Defines expected parameters, their types, and constraints
  - Must include `"type": "object"` at the root level
  - Should include `"required"` array for required parameters
  - Should include `"additionalProperties": false` to reject extra fields
- `strict` (boolean, optional, default: false): Enable strict mode
  - When `true`, enforces exact schema adherence
  - Requires all object properties to be in `required` array
  - Requires `additionalProperties: false` at all nesting levels
  - Limits flexibility but increases reliability

**Validation Rules**:
1. `name` must match pattern `^[a-zA-Z0-9_-]+$`
2. `parameters` must be valid JSON Schema
3. `parameters.type` must be `"object"`
4. If `strict: true`, schema must meet strict mode requirements:
   - All object properties must be required
   - `additionalProperties` must be `false` at all levels
   - Maximum 100 properties total
   - Maximum 5 levels of nesting

**Example**:
```json
{
  "name": "read_file",
  "description": "Read the contents of a file at the specified path",
  "parameters": {
    "type": "object",
    "properties": {
      "path": {
        "type": "string",
        "description": "Absolute or relative path to the file"
      },
      "encoding": {
        "type": "string",
        "enum": ["utf-8", "ascii", "utf-16"],
        "description": "File encoding"
      }
    },
    "required": ["path"],
    "additionalProperties": false
  }
}
```

---

### 6. Stream Options

Configuration for streaming responses with additional data.

**Fields**:
- `include_usage` (boolean, required): Whether to include usage statistics
  - When `true`, final streaming chunk includes token usage
  - When `false`, no usage statistics in stream
  - Default: `false`

**Relationships**:
- Belongs to a Chat Completion Request
- Affects the final chunk in streaming responses

**Behavior**:
- When enabled, the final chunk before `[DONE]` includes a `usage` object
- Usage object contains `prompt_tokens`, `completion_tokens`, `total_tokens`

---

### 7. Chat Completion Request

The top-level request object for chat completions with tool support.

**Fields**:

**Core Parameters** (always supported):
- `model` (string, required): Model identifier to use
  - Examples: `"gpt-oss-120b"`, `"deepseek-coder-33b-instruct"`
  - Validation: Must match a supported model
- `messages` (array of Chat Message, required): Conversation history
  - Must contain at least one message
  - Messages must be in chronological order
  - Tool messages must follow assistant messages with tool_calls

**Standard Parameters**:
- `stream` (boolean, optional, default: false): Enable streaming
- `max_tokens` (integer, optional): Maximum tokens to generate
  - Validation: Must be positive integer
- `temperature` (number, optional, default: 1.0): Sampling temperature
  - Range: 0.0 to 2.0
  - Validation: Must be non-negative number
- `top_p` (number, optional, default: 1.0): Nucleus sampling
  - Range: 0.0 to 1.0
  - Validation: Must be between 0 and 1
- `stop` (string or array of strings, optional): Stop sequences

**Tool Calling Parameters** (NEW):
- `tools` (array of Tool Definition, optional): Available functions
  - Can be empty array or omitted if no tools needed
  - Maximum recommended: 50-100 tools for performance
- `tool_choice` (string or object, optional): Tool selection strategy
  - String values: `"auto"`, `"none"`, `"required"`
  - Object value: `{"type": "function", "function": {"name": "<func_name>"}}`
  - Default: `"auto"` when tools provided
  - Validation:
    - If string, must be `"auto"`, `"none"`, or `"required"`
    - If object, function name must exist in `tools` array
- `parallel_tool_calls` (boolean, optional, default: true): Allow parallel execution
  - When `true`, assistant can call multiple tools in one response
  - When `false`, maximum one tool call per response
  - Must be `false` when using `strict: true` in tool definitions

**Streaming Parameters** (NEW):
- `stream_options` (Stream Options, optional): Streaming configuration
  - Only relevant when `stream: true`
  - Enables usage statistics in streaming mode

**Extended Parameters** (forward compatibility):
- `reasoning_effort` (string, optional): Reasoning intensity
  - Values: `"low"`, `"medium"`, `"high"`
  - Not yet implemented, accepted for forward compatibility
- Additional fields accepted gracefully (not validated, not forwarded to backend)

**Validation Rules**:
1. `model` must be non-empty string
2. `messages` must contain at least one message
3. `messages` must maintain valid role order (no tool messages without preceding tool_calls)
4. If `tools` provided and `tool_choice` is object, function name must exist in tools
5. If `stream_options` provided, `stream` must be `true`
6. `temperature` must be >= 0
7. `top_p` must be between 0 and 1
8. `max_tokens` must be positive integer if provided

**Relationships**:
- Contains multiple Chat Messages
- Contains multiple Tool Definitions (optional)
- Contains one Stream Options object (optional)

---

### 8. Chat Completion Response

The response object returned for chat completions with tool calls.

**Fields**:
- `id` (string, required): Unique response identifier
  - Format: `"chatcmpl-<random_id>"`
  - Example: `"chatcmpl-abc123xyz"`
- `object` (string, required): Object type
  - Value: `"chat.completion"` for non-streaming
  - Value: `"chat.completion.chunk"` for streaming
- `created` (integer, required): Unix timestamp of creation
- `model` (string, required): Model used for generation
- `choices` (array of Choice, required): Generated responses
  - Typically contains one choice
  - Array to support future multi-choice scenarios
- `usage` (Usage Statistics, optional): Token consumption
  - Present in non-streaming responses
  - Present in final streaming chunk if `include_usage: true`

**Relationships**:
- Contains multiple Choices (typically one)
- Contains one Usage Statistics object

---

### 9. Choice

Represents a single generated response option.

**Fields**:
- `index` (integer, required): Choice index in array
  - Typically `0` for single-choice responses
- `message` (Chat Message, required, non-streaming): Complete response message
  - Contains `role`, `content`, and/or `tool_calls`
  - Only present in non-streaming responses
- `delta` (Chat Message partial, required, streaming): Incremental message update
  - Contains partial `content` or `tool_calls`
  - Only present in streaming chunks
- `finish_reason` (string, required): Why generation stopped
  - Values:
    - `"stop"`: Natural completion or stop sequence reached
    - `"tool_calls"`: Assistant requested function calls
    - `"length"`: Maximum token limit reached
    - `null`: Generation not finished (streaming only)

**Validation Rules**:
1. `finish_reason` must be `"tool_calls"` when `message.tool_calls` is present
2. `finish_reason` is `null` for all streaming chunks except the last
3. Non-streaming must have `message`, not `delta`
4. Streaming must have `delta`, not `message`

---

### 10. Usage Statistics

Token consumption metrics for the request/response.

**Fields**:
- `prompt_tokens` (integer, required): Tokens in the prompt
  - Includes all messages, tool definitions, system prompt
- `completion_tokens` (integer, required): Tokens in the completion
  - Includes generated text and tool call structures
- `total_tokens` (integer, required): Sum of prompt and completion tokens
  - Validation: Must equal `prompt_tokens + completion_tokens`

**Calculation Notes**:
- Tool definitions add tokens to prompt count
- Tool call JSON structures add tokens to completion count
- Streaming mode: Usage calculated at end, included in final chunk if requested

---

## Entity Relationships

```
Chat Completion Request
├── messages: Chat Message[]
│   ├── role: string
│   ├── content?: string
│   ├── tool_calls?: Tool Call[]
│   │   ├── id: string
│   │   ├── type: "function"
│   │   └── function: Function Invocation
│   │       ├── name: string
│   │       └── arguments: string (JSON)
│   └── tool_call_id?: string
├── tools?: Tool Definition[]
│   ├── type: "function"
│   └── function: Tool Function
│       ├── name: string
│       ├── description?: string
│       ├── parameters: JSON Schema
│       └── strict?: boolean
├── tool_choice?: string | object
├── parallel_tool_calls?: boolean
└── stream_options?: Stream Options
    └── include_usage: boolean

Chat Completion Response
├── id: string
├── choices: Choice[]
│   ├── message: Chat Message (non-streaming)
│   ├── delta: Chat Message partial (streaming)
│   └── finish_reason: string | null
└── usage?: Usage Statistics
    ├── prompt_tokens: integer
    ├── completion_tokens: integer
    └── total_tokens: integer
```

---

## Conversation Flow

### Simple Tool Call (Single Turn)

```
Request:
  messages: [
    {role: "user", content: "Read /tmp/test.txt"}
  ]
  tools: [
    {type: "function", function: {name: "read_file", ...}}
  ]

Response:
  choices: [
    {
      message: {
        role: "assistant",
        content: null,
        tool_calls: [
          {id: "call_123", function: {name: "read_file", arguments: "{\"path\":\"/tmp/test.txt\"}"}}
        ]
      },
      finish_reason: "tool_calls"
    }
  ]
```

### Multi-Turn Tool Conversation

```
Turn 1 Request:
  messages: [{role: "user", content: "Read /tmp/test.txt"}]
  tools: [...]

Turn 1 Response:
  message: {tool_calls: [{id: "call_123", ...}]}

Turn 2 Request:
  messages: [
    {role: "user", content: "Read /tmp/test.txt"},
    {role: "assistant", tool_calls: [{id: "call_123", ...}]},
    {role: "tool", tool_call_id: "call_123", content: "file contents"}
  ]

Turn 2 Response:
  message: {role: "assistant", content: "The file contains...", finish_reason: "stop"}
```

### Parallel Tool Calls

```
Request:
  messages: [{role: "user", content: "Read file1.txt and file2.txt"}]
  tools: [...]
  parallel_tool_calls: true

Response:
  message: {
    tool_calls: [
      {id: "call_1", function: {name: "read_file", arguments: "{\"path\":\"file1.txt\"}"}},
      {id: "call_2", function: {name: "read_file", arguments: "{\"path\":\"file2.txt\"}"}}
    ]
  }

Next Request:
  messages: [
    {...},
    {role: "assistant", tool_calls: [...]},
    {role: "tool", tool_call_id: "call_1", content: "contents of file1"},
    {role: "tool", tool_call_id: "call_2", content: "contents of file2"}
  ]
```

---

## Validation Summary

### Request Validation

| Field | Validation Rules |
|-------|-----------------|
| `model` | Required, non-empty string |
| `messages` | Required, array with at least one message |
| `messages[].role` | Required, one of: system/user/assistant/tool |
| `messages[].content` | Optional for assistant with tool_calls, required for tool |
| `messages[].tool_call_id` | Required for role: tool, must match previous tool call |
| `tools` | Optional array of tool definitions |
| `tools[].function.name` | Required, matches `^[a-zA-Z0-9_-]+$` |
| `tools[].function.parameters` | Required, valid JSON Schema with type: object |
| `tool_choice` | Optional, "auto"/"none"/"required" or specific tool object |
| `parallel_tool_calls` | Optional boolean |
| `temperature` | Optional, >= 0 |
| `top_p` | Optional, 0-1 range |
| `max_tokens` | Optional, positive integer |

### Response Validation

| Field | Validation Rules |
|-------|-----------------|
| `id` | Required, format: `chatcmpl-<id>` |
| `choices[].message.tool_calls[].id` | Required, format: `call_<id>` |
| `choices[].message.tool_calls[].function.arguments` | Required, valid JSON string |
| `choices[].finish_reason` | Must be "tool_calls" when tool_calls present |
| `usage.total_tokens` | Must equal prompt_tokens + completion_tokens |

---

## Implementation Notes

### Pydantic Models (Python)

```python
from pydantic import BaseModel, ConfigDict, Field
from typing import Optional, List, Dict, Any, Union

class ChatMessage(BaseModel):
    model_config = ConfigDict(extra='allow')

    role: str
    content: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None
    name: Optional[str] = None

class ToolFunction(BaseModel):
    model_config = ConfigDict(extra='allow')

    name: str = Field(..., pattern=r'^[a-zA-Z0-9_-]+$')
    description: Optional[str] = None
    parameters: Dict[str, Any]
    strict: Optional[bool] = False

class Tool(BaseModel):
    model_config = ConfigDict(extra='allow')

    type: str = "function"
    function: ToolFunction

class ChatCompletionRequest(BaseModel):
    model_config = ConfigDict(extra='allow')

    model: str
    messages: List[ChatMessage]
    stream: bool = False

    max_tokens: Optional[int] = None
    temperature: Optional[float] = 1.0
    top_p: Optional[float] = 1.0
    stop: Optional[Union[str, List[str]]] = None

    tools: Optional[List[Tool]] = None
    tool_choice: Optional[Union[str, Dict[str, Any]]] = None
    parallel_tool_calls: Optional[bool] = None
    stream_options: Optional[Dict[str, Any]] = None
```

---

## References

- Feature Spec: `/specs/003-cline-tool-calling/spec.md`
- Research: `/specs/003-cline-tool-calling/research.md`
- OpenAI API Reference: https://platform.openai.com/docs/api-reference/chat/create

**Last Updated**: 2025-11-12
