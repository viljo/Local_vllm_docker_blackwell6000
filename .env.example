# API Authentication
# Generate a secure key with: python3 -c "import secrets; print('sk-local-' + secrets.token_hex(32))"
API_KEY=sk-local-CHANGE-THIS-TO-A-SECURE-RANDOM-KEY

# Model Configuration
PYTHON_MODEL=TheBloke/deepseek-coder-33B-instruct-AWQ
GENERAL_MODEL=TheBloke/Mistral-7B-v0.1-AWQ

# Service Ports
ROUTER_PORT=8080
WEBUI_PORT=3000
CODER_BACKEND_PORT=8000
GENERAL_BACKEND_PORT=8001
METRICS_PORT=9090

# Performance Tuning
CODER_GPU_MEMORY=0.45
GENERAL_GPU_MEMORY=0.40
CODER_MAX_SEQ=64
GENERAL_MAX_SEQ=128

# vLLM Configuration
CODER_MAX_MODEL_LEN=4096
GENERAL_MAX_MODEL_LEN=4096
CODER_MAX_BATCHED_TOKENS=8192
GENERAL_MAX_BATCHED_TOKENS=8192

# Logging
LOG_LEVEL=INFO
LOG_RETENTION_DAYS=7
LOG_MAX_SIZE_GB=10

# Docker Configuration
COMPOSE_PROJECT_NAME=local-llm-service
